{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "k0vSRVgGC1cE",
        "o_c-p9P7BGDd"
      ],
      "authorship_tag": "ABX9TyMfnYQjXwYzkpVBT5u5YcZr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TienNguyen93/clinical-generation/blob/main/clinical_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clinical Note Generation**"
      ],
      "metadata": {
        "id": "ljkS5CWwuGPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install datasets evaluate rouge_score"
      ],
      "metadata": {
        "id": "UB-98Z0grPsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import libraries**"
      ],
      "metadata": {
        "id": "swN0_wZ-xl1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
        "import torch\n",
        "import time\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "z2W0C6UyxlX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load dataset**"
      ],
      "metadata": {
        "id": "Hq5ybqksrMQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"316usman/research_clinical_visit_note_summarization_corpus_mts\")"
      ],
      "metadata": {
        "id": "NNs_HBfohRK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "id": "kkVk2eyMrnGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Find out the longest sequence and shortest sequence in train, val, tes set**"
      ],
      "metadata": {
        "id": "aj5FGf5RHiDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "_v5ywsJJHg_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Prepare dataset**"
      ],
      "metadata": {
        "id": "cIysmpx56HLM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Convert the dialog-summary (prompt-response) pairs into explicit instructions"
      ],
      "metadata": {
        "id": "9OA6X9IVEE24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Preprocessing function needs to:\n",
        "\n",
        "* Prefix the input with a prompt so T5 knows this is a summarization task. Some models capable of multiple NLP tasks require prompting for specific tasks.\n",
        "* Use the keyword text_target argument when tokenizing labels.\n",
        "* Truncate sequences to be no longer than the maximum length set by the max_length parameter.\n",
        "\"\"\"\n",
        "\n",
        "# tokenize function\n",
        "def t5_tokenize_function(example):\n",
        "    start_prompt = 'Summarize the following conversation.\\n\\n'\n",
        "    end_prompt = '\\n\\nSummary: '\n",
        "\n",
        "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"prompt\"]]\n",
        "\n",
        "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "    example['labels'] = tokenizer(example[\"completion\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    return example"
      ],
      "metadata": {
        "id": "ZrK4WKrV6aeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load models**"
      ],
      "metadata": {
        "id": "1ybnaCdzskvu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **T5 model**"
      ],
      "metadata": {
        "id": "BFf7VZnWEX77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load T5 model\n",
        "t5_name ='google/flan-t5-base'\n",
        "t5_model = AutoModelForSeq2SeqLM.from_pretrained(t5_name)\n",
        "\n",
        "# T5 tokenizer\n",
        "# parameter use_fast switches on fast tokenizer\n",
        "t5_tokenizer = AutoTokenizer.from_pretrained(t5_name, use_fast=True)"
      ],
      "metadata": {
        "id": "Vmn4VPE3EiFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply tokenization\n",
        "t5_tokenized_ds = ds.map(t5_tokenize_function, batched=True)\n",
        "t5_tokenized_ds = t5_tokenized_ds.remove_columns(['prompt', 'completion'])"
      ],
      "metadata": {
        "id": "q9vje5zNHGEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t5_tokenized_ds = t5_tokenized_ds.filter(lambda example, index: index % 100 == 0, with_indices=True)\n",
        "\n",
        "# check shape\n",
        "print(f\"Shapes of the datasets:\")\n",
        "print(f\"Training: {t5_tokenized_ds['train'].shape}\")\n",
        "print(f\"Validation: {t5_tokenized_ds['validation'].shape}\")\n",
        "print(f\"Test: {t5_tokenized_ds['test'].shape}\")"
      ],
      "metadata": {
        "id": "Gh86w3mjFI_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5_tokenized_ds"
      ],
      "metadata": {
        "id": "YIs_Onykjzb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        " create a batch of examples using DataCollatorForSeq2Seq.\n",
        " Itâ€™s more efficient to dynamically pad the sentences to the longest length in a batch during collation,\n",
        " instead of padding the whole dataset to the maximum length.\n",
        "\"\"\"\n",
        "\n",
        "# from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "# data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
      ],
      "metadata": {
        "id": "d5_wvKXPb1Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fine-tune T5"
      ],
      "metadata": {
        "id": "7gzFvEyoLmrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir=\"./results\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    learning_rate=1e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    per_device_train_batch_size=8,\n",
        "    auto_find_batch_size=True,\n",
        "    logging_steps=10,\n",
        "    # max_steps=1,\n",
        "    eval_strategy='epoch',\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=t5_model,\n",
        "    tokenizer=t5_tokenizer,\n",
        "    args=training_args,\n",
        "    train_dataset=t5_tokenized_ds['train'],\n",
        "    eval_dataset=t5_tokenized_ds['validation']\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "PbGQn3bVHMIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5_instruct_model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/results/checkpoint-903\")"
      ],
      "metadata": {
        "id": "vfm7loJpcjnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate the T5 Qualitatively"
      ],
      "metadata": {
        "id": "sSH4FGpVv5hJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = 100\n",
        "dialogue = ds['test'][index]['prompt']\n",
        "human_baseline_summary = ds['test'][index]['completion']\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "input_ids = t5_tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "t5_res = t5_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "t5_text_res = t5_tokenizer.decode(t5_res[0], skip_special_tokens=True)\n",
        "\n",
        "t5_instruct_res = t5_instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "t5_instruct_text_res = t5_tokenizer.decode(t5_instruct_res[0], skip_special_tokens=True)\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{human_baseline_summary}')\n",
        "print(dash_line)\n",
        "print(f'ORIGINAL MODEL:\\n{t5_text_res}')\n",
        "print(dash_line)\n",
        "print(f'INSTRUCT MODEL:\\n{t5_instruct_text_res}')"
      ],
      "metadata": {
        "id": "VG5TEvEev0kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate the T5 Quantitatively"
      ],
      "metadata": {
        "id": "EdSvSUn_y1fu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mEkFGycaG3us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROUGE Metric"
      ],
      "metadata": {
        "id": "tmop_TqmzTY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = evaluate.load('rouge')"
      ],
      "metadata": {
        "id": "WkXwPVrXv0aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialogues = ds['test'][0:3]['prompt']\n",
        "human_baseline_summaries = ds['test'][0:3]['completion']\n",
        "\n",
        "original_model_summaries = []\n",
        "instruct_model_summaries = []\n",
        "\n",
        "for _, dialogue in enumerate(dialogues):\n",
        "    prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary: \"\"\"\n",
        "    input_ids = t5_tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    original_model_outputs = t5_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    original_model_text_output = t5_tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "    original_model_summaries.append(original_model_text_output)\n",
        "\n",
        "    instruct_model_outputs = t5_instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    instruct_model_text_output = t5_tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "    instruct_model_summaries.append(instruct_model_text_output)\n",
        "\n",
        "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries))\n",
        "\n",
        "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries'])\n",
        "df"
      ],
      "metadata": {
        "id": "2dzE3uZm0tlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('INSTRUCT MODEL:')\n",
        "print(instruct_model_results)"
      ],
      "metadata": {
        "id": "eCdRuD4u1le_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERTScore, and"
      ],
      "metadata": {
        "id": "ySm_IwxMzWQj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EYwlw6MGzbuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLEURT"
      ],
      "metadata": {
        "id": "rXldUS66zY0N"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B_VfwOnnzbPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **BART**"
      ],
      "metadata": {
        "id": "RhHtgrSTEi0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load BART model\n",
        "bart_name = 'facebook/bart-large-cnn'\n",
        "bart_model = AutoModelForSeq2SeqLM.from_pretrained(bart_name)\n",
        "\n",
        "# BART tokenizer\n",
        "bart_tokenizer = AutoTokenizer.from_pretrained(bart_name, use_fast=True)"
      ],
      "metadata": {
        "id": "hyiW-Xh8Eo5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bart_tokenize_function(example):\n",
        "    start_prompt = 'Summarize the following conversation.\\n\\n'\n",
        "    end_prompt = '\\n\\nSummary: '\n",
        "\n",
        "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"prompt\"]]\n",
        "\n",
        "    model_inputs = bart_tokenizer(prompt, padding=\"max_length\", truncation=True, max_length=512)\n",
        "    labels = bart_tokenizer(example[\"completion\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    # example['input_ids'] = bart_tokenizer(prompt, padding=\"max_length\", truncation=True,  max_length=512)\n",
        "    # example['labels'] = bart_tokenizer(example[\"completion\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "    # return example"
      ],
      "metadata": {
        "id": "3tkLblGAGcb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bart_tokenizer.pad_token = bart_tokenizer.eos_token\n",
        "\n",
        "# apply tokenization\n",
        "bart_tokenized_ds = ds.map(bart_tokenize_function, batched=True)\n",
        "bart_tokenized_ds = bart_tokenized_ds.remove_columns(['prompt', 'completion'])"
      ],
      "metadata": {
        "id": "XyPe9vorE9Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args_bart = TrainingArguments(\n",
        "    output_dir='./bart-clinical',\n",
        "    learning_rate=1e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    per_device_train_batch_size=8,\n",
        "    auto_find_batch_size=True,\n",
        "    logging_steps=10,\n",
        "    # max_steps=1,\n",
        "    eval_strategy='epoch',\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer_bart = Trainer(\n",
        "    model=bart_model,\n",
        "    tokenizer=bart_tokenizer,\n",
        "    args=training_args_bart,\n",
        "    train_dataset=bart_tokenized_ds['train'],\n",
        "    eval_dataset=bart_tokenized_ds['validation']\n",
        ")\n",
        "\n",
        "trainer_bart.train()"
      ],
      "metadata": {
        "id": "kpmOqC9UKhBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluation**"
      ],
      "metadata": {
        "id": "k0vSRVgGC1cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ROUGE, BERTScore, and BLEURT."
      ],
      "metadata": {
        "id": "XJMDs8h9C8qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Examples**"
      ],
      "metadata": {
        "id": "o_c-p9P7BGDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **View an instance of dialogue**"
      ],
      "metadata": {
        "id": "LtNxvxj0r5zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_indices = [40, 200]\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "\n",
        "for i, index in enumerate(example_indices):\n",
        "    print(dash_line)\n",
        "    print('Example ', i + 1)\n",
        "    print(dash_line)\n",
        "    print('INPUT DIALOGUE:')\n",
        "    print(ds['test'][index]['prompt'])\n",
        "    print(dash_line)\n",
        "    print('BASELINE HUMAN SUMMARY:')\n",
        "    print(ds['test'][index]['completion'])\n",
        "    print(dash_line)\n",
        "    print()"
      ],
      "metadata": {
        "id": "9ugtbjB9sXEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test tokenizer\n",
        "sentence = \"What time is it, Tom?\"\n",
        "\n",
        "sentence_encoded = t5_tokenizer(sentence, return_tensors='pt')\n",
        "\n",
        "sentence_decoded = t5_tokenizer.decode(\n",
        "        sentence_encoded[\"input_ids\"][0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "print('ENCODED SENTENCE:')\n",
        "print(sentence_encoded[\"input_ids\"][0])\n",
        "print('\\nDECODED SENTENCE:')\n",
        "print(sentence_decoded)"
      ],
      "metadata": {
        "id": "GUq8UzJQXMec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Summarize Dialogue without Prompt Engineering**"
      ],
      "metadata": {
        "id": "GKmPPFhtq0Ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, (tokenizer, model) in models.items():\n",
        "  print(\"Model:\", model_name)\n",
        "\n",
        "  for i, index in enumerate(example_indices):\n",
        "      dialogue = ds['test'][index]['prompt']\n",
        "      summary = ds['test'][index]['completion']\n",
        "\n",
        "      # tokenization\n",
        "      inputs = tokenizer(dialogue, return_tensors='pt')\n",
        "      output = tokenizer.decode(\n",
        "          model.generate(\n",
        "              inputs[\"input_ids\"],\n",
        "              max_new_tokens=50,\n",
        "          )[0],\n",
        "          skip_special_tokens=True\n",
        "      )\n",
        "\n",
        "      print(dash_line)\n",
        "      print('Example ', i + 1)\n",
        "      print(dash_line)\n",
        "      print(f'INPUT PROMPT:\\n{dialogue}')\n",
        "      print(dash_line)\n",
        "      print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
        "      print(dash_line)\n",
        "      print(f'MODEL GENERATION - WITHOUT PROMPT ENGINEERING:\\n{output}\\n')"
      ],
      "metadata": {
        "id": "zwqLiKhpIqoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Summarize Dialogue with an Instruction Prompt**"
      ],
      "metadata": {
        "id": "mzLNR0kRqGE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero Shot Inference with an Instruction Prompt"
      ],
      "metadata": {
        "id": "HkgUiWV1qO4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, (tokenizer, model) in models.items():\n",
        "  print(\"Model:\", model_name)\n",
        "\n",
        "  for i, index in enumerate(example_indices):\n",
        "      dialogue = ds['test'][index]['prompt']\n",
        "      summary = ds['test'][index]['completion']\n",
        "\n",
        "      prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary:\n",
        "    \"\"\"\n",
        "\n",
        "      # tokenization\n",
        "      inputs = tokenizer(prompt, return_tensors='pt')\n",
        "      output = tokenizer.decode(\n",
        "          model.generate(\n",
        "              inputs[\"input_ids\"],\n",
        "              max_new_tokens=50,\n",
        "          )[0],\n",
        "          skip_special_tokens=True\n",
        "      )\n",
        "\n",
        "      print(dash_line)\n",
        "      print('Example ', i + 1)\n",
        "      print(dash_line)\n",
        "      print(f'INPUT PROMPT:\\n{prompt}')\n",
        "      print(dash_line)\n",
        "      print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
        "      print(dash_line)\n",
        "      print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')"
      ],
      "metadata": {
        "id": "7zNmIje_tIiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero Shot Inference with the Prompt Template"
      ],
      "metadata": {
        "id": "m_EYaM28qVvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, (tokenizer, model) in models.items():\n",
        "  print(\"Model:\", model_name)\n",
        "\n",
        "  for i, index in enumerate(example_indices):\n",
        "      dialogue = ds['test'][index]['prompt']\n",
        "      summary = ds['test'][index]['completion']\n",
        "\n",
        "      prompt = f\"\"\"\n",
        "Dialogue:\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "What was going on?\n",
        "\"\"\"\n",
        "\n",
        "      # tokenization\n",
        "      inputs = tokenizer(prompt, return_tensors='pt')\n",
        "      output = tokenizer.decode(\n",
        "          model.generate(\n",
        "              inputs[\"input_ids\"],\n",
        "              max_new_tokens=50,\n",
        "          )[0],\n",
        "          skip_special_tokens=True\n",
        "      )\n",
        "\n",
        "      print(dash_line)\n",
        "      print('Example ', i + 1)\n",
        "      print(dash_line)\n",
        "      print(f'INPUT PROMPT:\\n{prompt}')\n",
        "      print(dash_line)\n",
        "      print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
        "      print(dash_line)\n",
        "      print(f'MODEL GENERATION - ZERO SHOT (another template):\\n{output}\\n')"
      ],
      "metadata": {
        "id": "790aOzhtvGOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Summarize Dialogue with One Shot and Few Shot Inference**"
      ],
      "metadata": {
        "id": "uMFmsAVZwTsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One Shot Inference"
      ],
      "metadata": {
        "id": "pA-az9Jjwg4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prompt(example_indices_full, example_index_to_summarize):\n",
        "    prompt = ''\n",
        "    for index in example_indices_full:\n",
        "        dialogue = ds['test'][index]['prompt']\n",
        "        summary = ds['test'][index]['completion']\n",
        "\n",
        "        # The stop sequence '{summary}\\n\\n\\n' is important for FLAN-T5. Other models may have their own preferred stop sequence.\n",
        "        prompt += f\"\"\"\n",
        "Dialogue:\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "What was going on?\n",
        "{summary}\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    dialogue = ds['test'][example_index_to_summarize]['prompt']\n",
        "\n",
        "    prompt += f\"\"\"\n",
        "Dialogue:\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "What was going on?\n",
        "\"\"\"\n",
        "\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "iM3CaRIGwFCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_indices_full = [40]\n",
        "example_index_to_summarize = 200\n",
        "\n",
        "one_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
        "\n",
        "print(one_shot_prompt)"
      ],
      "metadata": {
        "id": "lBWUqc_Rw6AG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = ds['test'][example_index_to_summarize]['completion']\n",
        "\n",
        "inputs = t5_tokenizer(one_shot_prompt, return_tensors='pt')\n",
        "output = t5_tokenizer.decode(\n",
        "    t5_model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=50,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ONE SHOT:\\n{output}')"
      ],
      "metadata": {
        "id": "mZnMbU9Jxma6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few Shot Inference"
      ],
      "metadata": {
        "id": "Wtkj7T0fwmgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_indices_full = [40, 80, 120]\n",
        "example_index_to_summarize = 200\n",
        "\n",
        "few_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)\n",
        "\n",
        "print(few_shot_prompt)"
      ],
      "metadata": {
        "id": "A1yfyOVxwqaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = ds['test'][example_index_to_summarize]['completion']\n",
        "\n",
        "inputs = t5_tokenizer(few_shot_prompt, return_tensors='pt')\n",
        "output = t5_tokenizer.decode(\n",
        "    t5_model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=50,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - FEW SHOT:\\n{output}')"
      ],
      "metadata": {
        "id": "UgArOWp_yQaq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}